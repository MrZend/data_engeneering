{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f60a9c6-95fd-4fe9-882f-9dd3b934f64c",
   "metadata": {},
   "source": [
    "## Install neccessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24310d8a-e9fc-4790-bd39-567fb7e6b309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: delta-spark==3.2.0 in /opt/conda/lib/python3.11/site-packages (3.2.0)\n",
      "Requirement already satisfied: pyspark<3.6.0,>=3.5.0 in /usr/local/spark/python (from delta-spark==3.2.0) (3.5.0)\n",
      "Requirement already satisfied: importlib-metadata>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from delta-spark==3.2.0) (6.8.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata>=1.0.0->delta-spark==3.2.0) (3.17.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.11/site-packages (from pyspark<3.6.0,>=3.5.0->delta-spark==3.2.0) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install delta-spark==3.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02773fdc-6d5e-4947-9d22-3a7b44e120df",
   "metadata": {},
   "source": [
    "## Work with DeltaLake (CDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64a7240-c722-48f2-b342-3687c6d2ff44",
   "metadata": {},
   "source": [
    "### Import neccessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c4390b43-eea2-4d72-93c2-4b905f0a9d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType\n",
    "from delta import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6edb7a-bb98-4d96-b829-095d239b654d",
   "metadata": {},
   "source": [
    "### Initialize and set up spark to work with DeltaLake (CDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08283998-b441-430b-b680-cffd47835107",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = SparkSession.builder.appName(\"Delta Lake Implementation Lab\") \\\n",
    "                              .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "                              .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5d4f61-a041-48bc-b563-fa623e89a550",
   "metadata": {},
   "source": [
    "### Create schema of data and put first data to DeltaLake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98336130-0082-48ca-944c-aa2d9a27131a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+--------------+------------+-------------+---------+----------+\n",
      "|route_id|route_version|count_vehicles|vehicle_type|timetables_id|sum_delay|mean_delay|\n",
      "+--------+-------------+--------------+------------+-------------+---------+----------+\n",
      "|       1|            1|             0|     автобус|          101|      0.0|       0.0|\n",
      "|       1|            1|             0|   тролейбус|          102|      0.0|       0.0|\n",
      "|       2|            1|             0|     трамвай|          103|      0.0|       0.0|\n",
      "|       3|            1|             0|   тролейбус|          104|      0.0|       0.0|\n",
      "+--------+-------------+--------------+------------+-------------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    # id маршруту\n",
    "    StructField(\"route_id\", IntegerType(), nullable=False),\n",
    "    # Версія маршруту, яка буде братися з іншої гіпотетичної таблиці, де буде детально розписано всі зупинки маршруту\n",
    "    StructField(\"route_version\", IntegerType(), nullable=False),\n",
    "    # Кількість транспорту на маршруті наразі - теж можна вважати статистичним полем\n",
    "    StructField(\"count_vehicles\", IntegerType(), nullable=False),\n",
    "    # Тип транспорту -> автобус, трамвай, тролейбус тощо. Буде складником складеного ключа, оскільки ID маршрутів можуть бути одними тими самими для різних типів тр.\n",
    "    StructField(\"vehicle_type\", StringType(), nullable=False),\n",
    "    # id розкладу, яка буде силатися на іншу таблицю, де буде міститься детальна інформація про розклад\n",
    "    StructField(\"timetables_id\", IntegerType(), nullable=False),\n",
    "    # Сума часу затримки, яка буде враховувати всі виїзди транспорту на маршрут (буде мати статистику за певний день). Буде оновлюватися по прибуттю транспорту\n",
    "    # на кожну зупинку. В секундах\n",
    "    StructField(\"sum_delay\", FloatType(), nullable=False),\n",
    "    # Середня затримка, яка буде рахуватися відношенням між сумарною затримкою та кількістю виїздів транспорту на маршрут (буде мати статистику за певний день).\n",
    "    # Буде оновлюватися по прибуттю транспорту на кожну зупинку. В секундах\n",
    "    StructField(\"mean_delay\", FloatType(), nullable=False)\n",
    "])\n",
    "\n",
    "# Дана схема буде зберігати статистику про затримки певного маршруту, та буде оновлюватися при прибуттю на кожну зупинку (наприклад, за допомогою GPS-трекерів,\n",
    "# які активно впроваджуються в міський транспорт в місті Києві та можна переглядати місцеперебування певного транспорту за допомогою такої системи як EWay),\n",
    "# також кожного дня статистичні дані будуть обнулятися (наприклад, при першому виїзді транспорту кожного дня будуть обнулятися колонки sum_delay та mean_delay). \n",
    "# Тоді можна буде аналізувати затримки в розрізі днів, годин тощо. Або обʼєднавши дані з таблицею розкладу, аналізувати затримки між певними зупинками транспорту\n",
    "\n",
    "# Зімітуємо початок робочого дня, коли починають виходити перші транспорти на маршрути, тобто статистичні дані будуть містити нулі\n",
    "initial_data = [\n",
    "    (1, 1, 0, \"автобус\", 101, 0.0, 0.0),\n",
    "    (1, 1, 0, \"тролейбус\", 102, 0.0, 0.0),\n",
    "    (2, 1, 0, \"трамвай\", 103, 0.0, 0.0),\n",
    "    (3, 1, 0, \"тролейбус\", 104, 0.0, 0.0)\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(initial_data, schema=schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be03fdbf-5d17-4002-84ad-065e8e09bd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<delta.tables.DeltaTable at 0xffff50f35a10>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Створюємо Delta таблицю по раніше створеній схемі та включимо CDF\n",
    "DeltaTable.createIfNotExists(spark) \\\n",
    "          .tableName(\"vehicle_monitoring\") \\\n",
    "          .property(\"delta.enableChangeDataFeed\", \"true\") \\\n",
    "          .addColumns(schema) \\\n",
    "          .execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a755b93f-7f09-4674-a258-9896ef543cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запишемо перші дані в Delta таблицю\n",
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"vehicle_monitoring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85cbad82-e3a2-4666-bd9c-28e45b518f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+--------------+------------+-------------+---------+----------+\n",
      "|route_id|route_version|count_vehicles|vehicle_type|timetables_id|sum_delay|mean_delay|\n",
      "+--------+-------------+--------------+------------+-------------+---------+----------+\n",
      "|       3|            1|             0|   тролейбус|          104|      0.0|       0.0|\n",
      "|       1|            1|             0|   тролейбус|          102|      0.0|       0.0|\n",
      "|       2|            1|             0|     трамвай|          103|      0.0|       0.0|\n",
      "|       1|            1|             0|     автобус|          101|      0.0|       0.0|\n",
      "+--------+-------------+--------------+------------+-------------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Прочитаємо записані дані\n",
    "data_df = spark.read.format(\"delta\").table(\"vehicle_monitoring\")\n",
    "data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a6d6e2dc-74fe-468f-88a5-85ec5de8bf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+--------------+------------+-------------+---------+----------+\n",
      "|route_id|route_version|count_vehicles|vehicle_type|timetables_id|sum_delay|mean_delay|\n",
      "+--------+-------------+--------------+------------+-------------+---------+----------+\n",
      "|       1|            2|             0|     автобус|          105|      0.0|       0.0|\n",
      "|      28|            1|             0|     автобус|          110|      0.0|       0.0|\n",
      "+--------+-------------+--------------+------------+-------------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Створимо новий DataFrame (виявили, що змінилась версія маршруту для першого маршруту автобусів та оновився графік) та додамо новий маршрут\n",
    "updated_data = [\n",
    "    (1, 2, 0, \"автобус\", 105, 0.0, 0.0),\n",
    "    (28, 1, 0, \"автобус\", 110, 0.0, 0.0),\n",
    "]\n",
    "\n",
    "updated_df = spark.createDataFrame(updated_data, schema=schema)\n",
    "updated_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5287c59b-9875-4b14-9671-b06dcc3aac87",
   "metadata": {},
   "source": [
    "### Update information into Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "79c42277-0ced-43a7-8a32-9938ac3afc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отримаємо Delta таблицю (створеної раніше)\n",
    "delta_table = DeltaTable.forName(spark, \"vehicle_monitoring\")\n",
    "\n",
    "# Виконання merge (upsert) операції\n",
    "delta_table.alias(\"old_data\") \\\n",
    "           .merge(updated_df.alias(\"updated_data\"),\n",
    "                  \"old_data.route_id = updated_data.route_id AND old_data.vehicle_type = updated_data.vehicle_type\") \\\n",
    "           .whenMatchedUpdate(set={\n",
    "               \"route_version\": \"updated_data.route_version\",\n",
    "               \"count_vehicles\": \"updated_data.count_vehicles\",\n",
    "               \"timetables_id\": \"updated_data.timetables_id\",\n",
    "               \"sum_delay\": \"updated_data.sum_delay\",\n",
    "               \"mean_delay\": \"updated_data.mean_delay\"}) \\\n",
    "           .whenNotMatchedInsertAll() \\\n",
    "           .execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90007c44-231d-4c2f-b4b6-a522d2f76cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+--------------+------------+-------------+---------+----------+\n",
      "|route_id|route_version|count_vehicles|vehicle_type|timetables_id|sum_delay|mean_delay|\n",
      "+--------+-------------+--------------+------------+-------------+---------+----------+\n",
      "|       1|            2|             0|     автобус|          105|      0.0|       0.0|\n",
      "|      28|            1|             0|     автобус|          110|      0.0|       0.0|\n",
      "|       3|            1|             0|   тролейбус|          104|      0.0|       0.0|\n",
      "|       1|            1|             0|   тролейбус|          102|      0.0|       0.0|\n",
      "|       2|            1|             0|     трамвай|          103|      0.0|       0.0|\n",
      "+--------+-------------+--------------+------------+-------------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Перегляд оновленої інформації\n",
    "delta_table.toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "68ecedd6-5455-45c9-9c61-3f505204aab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+--------------+------------+-------------+---------+----------+\n",
      "|route_id|route_version|count_vehicles|vehicle_type|timetables_id|sum_delay|mean_delay|\n",
      "+--------+-------------+--------------+------------+-------------+---------+----------+\n",
      "|       1|            2|             2|     автобус|          105|     15.0|       7.5|\n",
      "|      28|            1|             2|     автобус|          110|     10.0|       5.0|\n",
      "|       1|            1|             1|   тролейбус|          102|      7.0|       7.0|\n",
      "|       2|            1|             1|     трамвай|          103|      0.0|       0.0|\n",
      "|       3|            1|             1|   тролейбус|          104|     20.0|      20.0|\n",
      "+--------+-------------+--------------+------------+-------------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Оновимо інформацію по кількості транспорту на маршруті та значення затримок на маршрутах після першої зупинки\n",
    "data_first_station = [\n",
    "    (1, 2, 2, \"автобус\", 105, 15.0, 7.5),\n",
    "    (28, 1, 2, \"автобус\", 110, 10.0, 5.0),\n",
    "    (1, 1, 1, \"тролейбус\", 102, 7.0, 7.0),\n",
    "    (2, 1, 1, \"трамвай\", 103, 0.0, 0.0),\n",
    "    (3, 1, 1, \"тролейбус\", 104, 20.0, 20.0)\n",
    "]\n",
    "\n",
    "data_first_station_df = spark.createDataFrame(data_first_station, schema=schema)\n",
    "data_first_station_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41cee129-2163-451a-a992-080aedfe7d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оновимо дані в Delta таблиці (використаємо раніше створений обʼєкт Delta таблиці)\n",
    "delta_table.alias(\"old_data\") \\\n",
    "           .merge(data_first_station_df.alias(\"updated_data\"),\n",
    "                  \"old_data.route_id = updated_data.route_id AND old_data.vehicle_type = updated_data.vehicle_type\") \\\n",
    "           .whenMatchedUpdate(set={\n",
    "               \"route_version\": \"updated_data.route_version\",\n",
    "               \"count_vehicles\": \"updated_data.count_vehicles\",\n",
    "               \"timetables_id\": \"updated_data.timetables_id\",\n",
    "               \"sum_delay\": \"updated_data.sum_delay\",\n",
    "               \"mean_delay\": \"updated_data.mean_delay\"}) \\\n",
    "           .whenNotMatchedInsertAll() \\\n",
    "           .execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e1987644-d5a5-48a2-bcad-a79eed4307f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+--------------+------------+-------------+---------+----------+\n",
      "|route_id|route_version|count_vehicles|vehicle_type|timetables_id|sum_delay|mean_delay|\n",
      "+--------+-------------+--------------+------------+-------------+---------+----------+\n",
      "|       1|            2|             2|     автобус|          105|     15.0|       7.5|\n",
      "|       1|            1|             1|   тролейбус|          102|      7.0|       7.0|\n",
      "|       2|            1|             1|     трамвай|          103|      0.0|       0.0|\n",
      "|       3|            1|             1|   тролейбус|          104|     20.0|      20.0|\n",
      "|      28|            1|             2|     автобус|          110|     10.0|       5.0|\n",
      "+--------+-------------+--------------+------------+-------------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Перегляд оновленої інформації\n",
    "delta_table.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1184633e-70bf-40a1-97dd-0318c4a8d6d0",
   "metadata": {},
   "source": [
    "### Check history of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ed47c253-f7bf-4464-8b12-49c37327d335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------+--------+--------------------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "|version|           timestamp|userId|userName|           operation| operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n",
      "+-------+--------------------+------+--------+--------------------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "|      3|2025-01-05 18:53:...|  NULL|    NULL|               MERGE|{predicate -> [\"(...|NULL|    NULL|     NULL|          2|  Serializable|        false|{numTargetRowsCop...|        NULL|Apache-Spark/3.5....|\n",
      "|      2|2025-01-05 18:53:...|  NULL|    NULL|               MERGE|{predicate -> [\"(...|NULL|    NULL|     NULL|          1|  Serializable|        false|{numTargetRowsCop...|        NULL|Apache-Spark/3.5....|\n",
      "|      1|2025-01-05 18:53:...|  NULL|    NULL|CREATE OR REPLACE...|{partitionBy -> [...|NULL|    NULL|     NULL|          0|  Serializable|        false|{numFiles -> 5, n...|        NULL|Apache-Spark/3.5....|\n",
      "|      0|2025-01-05 18:52:...|  NULL|    NULL|        CREATE TABLE|{partitionBy -> [...|NULL|    NULL|     NULL|       NULL|  Serializable|         true|                  {}|        NULL|Apache-Spark/3.5....|\n",
      "+-------+--------------------+------+--------+--------------------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Подивимось всі версії даних в Delta таблиці\n",
    "delta_table.history().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "746e0c80-2ea7-4a5f-b517-00b166a107cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+--------------+------------+-------------+---------+----------+\n",
      "|route_id|route_version|count_vehicles|vehicle_type|timetables_id|sum_delay|mean_delay|\n",
      "+--------+-------------+--------------+------------+-------------+---------+----------+\n",
      "|       1|            2|             0|     автобус|          105|      0.0|       0.0|\n",
      "|      28|            1|             0|     автобус|          110|      0.0|       0.0|\n",
      "|       3|            1|             0|   тролейбус|          104|      0.0|       0.0|\n",
      "|       1|            1|             0|   тролейбус|          102|      0.0|       0.0|\n",
      "|       2|            1|             0|     трамвай|          103|      0.0|       0.0|\n",
      "+--------+-------------+--------------+------------+-------------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Повернемось до попередньої версії Delta таблиці (Застосування: наприклад, для перегляду інформації про затримки попереднього дня)\n",
    "previous_version_df = spark.read.format(\"delta\").option(\"versionAsOf\", 2).table(\"vehicle_monitoring\")\n",
    "previous_version_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a422a65-e2a1-47d8-a513-29afb69fc7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+--------------+------------+-------------+---------+----------+----------------+---------------+-----------------------+\n",
      "|route_id|route_version|count_vehicles|vehicle_type|timetables_id|sum_delay|mean_delay|_change_type    |_commit_version|_commit_timestamp      |\n",
      "+--------+-------------+--------------+------------+-------------+---------+----------+----------------+---------------+-----------------------+\n",
      "|1       |2            |0             |автобус     |105          |0.0      |0.0       |update_preimage |3              |2025-01-05 18:53:24.436|\n",
      "|1       |2            |2             |автобус     |105          |15.0     |7.5       |update_postimage|3              |2025-01-05 18:53:24.436|\n",
      "|1       |1            |0             |тролейбус   |102          |0.0      |0.0       |update_preimage |3              |2025-01-05 18:53:24.436|\n",
      "|1       |1            |1             |тролейбус   |102          |7.0      |7.0       |update_postimage|3              |2025-01-05 18:53:24.436|\n",
      "|2       |1            |0             |трамвай     |103          |0.0      |0.0       |update_preimage |3              |2025-01-05 18:53:24.436|\n",
      "|2       |1            |1             |трамвай     |103          |0.0      |0.0       |update_postimage|3              |2025-01-05 18:53:24.436|\n",
      "|3       |1            |0             |тролейбус   |104          |0.0      |0.0       |update_preimage |3              |2025-01-05 18:53:24.436|\n",
      "|3       |1            |1             |тролейбус   |104          |20.0     |20.0      |update_postimage|3              |2025-01-05 18:53:24.436|\n",
      "|28      |1            |0             |автобус     |110          |0.0      |0.0       |update_preimage |3              |2025-01-05 18:53:24.436|\n",
      "|28      |1            |2             |автобус     |110          |10.0     |5.0       |update_postimage|3              |2025-01-05 18:53:24.436|\n",
      "|1       |1            |0             |автобус     |101          |0.0      |0.0       |update_preimage |2              |2025-01-05 18:53:11.274|\n",
      "|1       |2            |0             |автобус     |105          |0.0      |0.0       |update_postimage|2              |2025-01-05 18:53:11.274|\n",
      "|28      |1            |0             |автобус     |110          |0.0      |0.0       |insert          |2              |2025-01-05 18:53:11.274|\n",
      "|3       |1            |0             |тролейбус   |104          |0.0      |0.0       |insert          |1              |2025-01-05 18:53:02.833|\n",
      "|1       |1            |0             |тролейбус   |102          |0.0      |0.0       |insert          |1              |2025-01-05 18:53:02.833|\n",
      "|1       |1            |0             |автобус     |101          |0.0      |0.0       |insert          |1              |2025-01-05 18:53:02.833|\n",
      "|2       |1            |0             |трамвай     |103          |0.0      |0.0       |insert          |1              |2025-01-05 18:53:02.833|\n",
      "+--------+-------------+--------------+------------+-------------+---------+----------+----------------+---------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Для перегляду змін використаємо CDF (Застосування, для перегляду змін в інформації про затримки певного дня)\n",
    "history = spark.read.format(\"delta\") \\\n",
    "                .option(\"readChangeFeed\", \"true\") \\\n",
    "                .option(\"startingVersion\", \"0\") \\\n",
    "                .table(\"vehicle_monitoring\")\n",
    "\n",
    "history.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f66851-6799-4c4a-b9d3-2c75e20f00bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66b41f54-780c-4ed4-a906-1923ee020973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"DROP TABLE IF EXISTS vehicle_monitoring\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
